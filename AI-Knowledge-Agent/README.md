# AIâ€‘Knowledgeâ€‘Agent

A minimal, productionâ€‘ready **Internal Knowledge / Q&A Agent** built with **Node.js, PostgreSQL + pgvector, and OpenAI embeddings**.

The goal of this project is to ingest structured legal / policy documents (web pages, later PDFs & markdown), store them as semantic vectors, and enable accurate **RAGâ€‘based Q&A** over internal knowledge.

---

## âœ¨ What this project does

- Fetches **policy / legal webpages** (e.g. Stripe, GitHub, OpenAI, Cloudflare)
- Extracts clean text from HTML
- **Chunks** documents into overlapping segments
- Generates **embeddings** using OpenAI
- Stores chunks in **Postgres + pgvector**
- Prepares the foundation for a `/ask` endpoint (RAG)

This is intentionally simple, explicit, and inspectable â€” no magic frameworks.

---

## ğŸ§± Architecture (Highâ€‘level)

```
Web / Docs / PDFs
        â†“
Text Extraction
        â†“
Chunking (+ overlap)
        â†“
Embeddings (OpenAI)
        â†“
Postgres (pgvector)
        â†“
Semantic Retrieval (RAG)
        â†“
LLM Answer + Sources
```

---

## ğŸ“ Project Structure

```
AI-Knowledge-Agent/
â”‚
â”œâ”€ docker-compose.yml        # Postgres + pgvector
â”œâ”€ .env                     # Database + OpenAI config
â”œâ”€ package.json
â”œâ”€ sql/
â”‚   â””â”€ schema.sql            # documents / chunks tables
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ db.js                 # pg Pool + helpers
â”‚   â”‚
â”‚   â”œâ”€ rag/
â”‚   â”‚   â”œâ”€ chunker.js        # text â†’ chunks (+ overlap)
â”‚   â”‚   â””â”€ embedding.js      # OpenAI embeddings
â”‚   â”‚
â”‚   â””â”€ scripts/
â”‚       â”œâ”€ ingest_web.js     # Web ingestion pipeline
â”‚       â””â”€ test_db_via_minimal.js  # Test DB
â”‚
â”‚
â””â”€ README.md
```

---

## âš™ï¸ Prerequisites

- Node.js â‰¥ 18
- Docker Desktop
- OpenAI API key

---

## ğŸ³ Postgres + pgvector (Docker)

We run Postgres in Docker to:

- avoid local version conflicts
- guarantee pgvector availability
- keep dev environment reproducible

### Start database

```bash
docker compose up -d
```

Database is exposed on **port 5433** to avoid conflicts with local Postgres.

---

## ğŸ—„ï¸ Database Schema

`sql/schema.sql` creates two core tables:

- **documents** â€” one row per source (URL, file)
- **chunks** â€” chunked text + embedding vectors

```sql
documents(id, source, title, created_at)
chunks(id, document_id, chunk_index, content, embedding, metadata)
```

Load schema:

```bash
Get-Content sql/schema.sql | docker exec -i rag_pg psql -U postgres -d ragdb
```

---

## ğŸ” Environment Variables

`.env`

```env
DATABASE_URL=postgres://postgres:postgres@127.0.0.1:5433/ragdb
OPENAI_API_KEY=sk-...
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIM=1536
```

---

## âœ… Verify DB Connection

Minimal sanity check:

```bash
node src/scripts/test_db_minimal.js
```

Expected output:

```
Running minimal DB test...
DB OK: { now: ... }
```

---

## ğŸŒ Web Ingestion

Edit `src/scripts/ingest_web.js`:

```js
export const URLS = ["https://stripe.com/privacy"];
```

Run:

```bash
node src/scripts/ingest_web.js
```

Check results:

```bash
docker exec -it rag_pg psql -U postgres -d ragdb -c "SELECT COUNT(*) FROM documents;"
docker exec -it rag_pg psql -U postgres -d ragdb -c "SELECT COUNT(*) FROM chunks;"
```

---

## ğŸ§© Why chunking is required

Chunking is essential for RAG systems:

- LLMs have context limits
- Vector search works on **small semantic units**
- Overlap prevents cutting sentences / definitions

Current strategy:

- ~1600 characters per chunk
- ~200 character overlap

Later improvements:

- Chunk by **headings / sections**
- Add `section_title` metadata (contracts, policies)

---

## ğŸ“„ Supported Sources

Currently:

- Web pages (HTML)

Planned:

- Markdown files (`docs/` folder)
- PDFs (policy / contracts)
- Internal docs

All sources share the same pipeline after text extraction.

---

## ğŸš€ Next Steps

Recommended order:

1. **Build `/ask` endpoint** (RAG Q&A)
2. Ingest all policy URLs
3. Add local docs / PDFs
4. Improve chunking (sectionâ€‘aware)
5. Add citations + source highlighting

---

## ğŸ¯ Use cases

- Internal compliance assistant
- Legal / policy Q&A
- Security & privacy reviews
- Developer documentation bots
- Regulator / audit tooling prototypes

---

## ğŸ§  Design Philosophy

- Explicit over magical
- SQL over abstractions
- Inspectable data
- Minimal dependencies

This is a **foundation**, not a blackâ€‘box product.

---

## ğŸ“œ License

MIT
