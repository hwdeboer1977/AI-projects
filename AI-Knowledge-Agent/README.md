# AIâ€‘Knowledgeâ€‘Agent

A **minimal fullâ€‘stack RAG (Retrievalâ€‘Augmented Generation) knowledge agent**.

It ingests legal / policy documents (web today, PDFs & markdown later), stores them as embeddings in **PostgreSQL + pgvector**, and exposes a clean **/ask API** with a simple **Next.js frontend**.

This project is intentionally explicit and debuggable â€” no heavy frameworks, no magic abstractions.

---

## âœ¨ What this project does

- Ingests **webâ€‘based legal / policy documents** (Stripe, GitHub, OpenAI, Cloudflare)
- Cleans and extracts readable text from HTML
- **Chunks** text into overlapping segments
- Generates **OpenAI embeddings**
- Stores everything in **Postgres + pgvector**
- Performs **semantic retrieval**
- Answers questions using **RAG** with citations
- Provides:
  - REST API (`/ask`)
  - Simple **Next.js frontend**

---

## ðŸ§± Highâ€‘level architecture

```
Web / Docs / PDFs
        â†“
Text Extraction
        â†“
Chunking (+ overlap)
        â†“
Embeddings (OpenAI)
        â†“
Postgres (pgvector)
        â†“
Retriever (topâ€‘K vectors)
        â†“
LLM Answer + Sources
        â†“
API (/ask) + Next.js UI
```

---

## ðŸ“ Project structure

```
AI-Knowledge-Agent/
â”‚
â”œâ”€ docker-compose.yml        # Postgres + pgvector (Docker)
â”œâ”€ .env                     # Backend secrets (NOT committed)
â”œâ”€ .gitignore
â”œâ”€ package.json             # Backend scripts
â”‚
â”œâ”€ sql/
â”‚   â””â”€ schema.sql            # documents / chunks tables
â”‚
â”œâ”€ src/
â”‚   â”œâ”€ backend/
â”‚   â”‚   â””â”€ server.js         # Express API (/health, /ask)
â”‚   â”‚
â”‚   â”œâ”€ rag/
â”‚   â”‚   â”œâ”€ chunker.js        # Text â†’ chunks (+ overlap)
â”‚   â”‚   â”œâ”€ embeddings.js    # OpenAI embeddings
â”‚   â”‚   â”œâ”€ retriever.js     # Vector similarity search
â”‚   â”‚   â””â”€ answer.js        # RAG answer generation
â”‚   â”‚
â”‚   â”œâ”€ scripts/
â”‚   â”‚   â”œâ”€ ingest_web.js    # Web ingestion pipeline
â”‚   â”‚   â””â”€ test_db_minimal.js
â”‚   â”‚
â”‚   â”œâ”€ db.js                # Postgres helper
â”‚   â”‚
â”‚   â””â”€ frontend/
â”‚       â””â”€ my-app/           # Next.js frontend
â”‚
â””â”€ README.md
```

---

## âš™ï¸ Prerequisites

- Node.js â‰¥ 18
- Docker Desktop
- OpenAI API key

---

## ðŸ³ Database (Postgres + pgvector)

We intentionally run Postgres in **Docker**:

- No local Postgres conflicts
- pgvector guaranteed
- Fully reproducible setup

### Start database

```bash
docker compose up -d
```

Database is exposed on **port 5433** (not 5432).

---

## ðŸ—„ï¸ Database schema

`sql/schema.sql` defines:

- **documents** â€” one row per source (URL / file)
- **chunks** â€” chunked text + embedding vectors

```sql
documents(id, source, title, created_at)
chunks(id, document_id, chunk_index, content, embedding, metadata)
```

Load schema:

```bash
Get-Content sql/schema.sql | docker exec -i rag_pg psql -U postgres -d ragdb
```

---

## ðŸ” Environment variables

Create `.env` **(never commit this)**:

```env
DATABASE_URL=postgres://postgres:postgres@127.0.0.1:5433/ragdb
OPENAI_API_KEY=sk-...
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIM=1536
CHAT_MODEL=gpt-4.1-mini
PORT=4000
```

`.env` is ignored via `.gitignore`.

---

## âœ… Verify DB connection

```bash
node src/scripts/test_db_minimal.js
```

Expected:

```
Running minimal DB test...
DB OK: { now: ... }
```

---

## ðŸŒ Web ingestion

Edit URLs in:

```js
src / scripts / ingest_web.js;
```

Example:

```js
export const URLS = ["https://stripe.com/privacy"];
```

Run ingestion:

```bash
node src/scripts/ingest_web.js
```

Verify:

```bash
docker exec -it rag_pg psql -U postgres -d ragdb -c "SELECT COUNT(*) FROM documents;"
docker exec -it rag_pg psql -U postgres -d ragdb -c "SELECT COUNT(*) FROM chunks;"
```

---

## ðŸ§© Why chunking is required

Chunking is **mandatory** for RAG:

- Vector search works on small semantic units
- LLMs have context limits
- Overlap prevents broken sentences

Current strategy:

- ~1600 characters per chunk
- ~200 character overlap

This applies to **web pages, PDFs, and markdown** alike.

---

## ðŸš€ Backend API

### Start backend

```bash
npm run dev
```

Server runs on:

```
http://localhost:4000
```

### Health check

```bash
GET /health
```

### Ask endpoint

```bash
POST /ask
Content-Type: application/json

{
  "question": "What is Stripe's privacy policy about data retention?"
}
```

Response:

```json
{
  "answer": "...",
  "sources": [
    { "ref": "#1", "source": "https://stripe.com/privacy", "distance": 0.12 }
  ]
}
```

Answers are **contextâ€‘restricted** and include citations.

---

## ðŸ–¥ï¸ Frontend (Next.js)

Frontend lives in:

```
src/frontend/my-app
```

### Start frontend

```bash
cd src/frontend/my-app
npm run dev
```

Open:

```
http://localhost:3000
```

The frontend calls the backend `/ask` endpoint.

---

## ðŸ§  Design philosophy

- Explicit > abstract
- SQL > blackâ€‘box vector DBs
- Inspectable embeddings
- Minimal dependencies

This is a **foundation**, not a SaaS product.

---

## ðŸ”œ Next steps

- Ingest all policy URLs
- Add markdown & PDF ingestion
- Improve sectionâ€‘aware chunking
- Add conversation memory
- Add auth / roles

---

## ðŸ“œ License

MIT
